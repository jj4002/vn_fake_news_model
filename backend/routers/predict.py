# routers/predict.py - FULL CODE (Removed risk assessment)

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional
import time
import logging

from services.supabase_client import SupabaseService
from services.rag_service import RAGService
from services.inference import HANONNXInference

logger = logging.getLogger(__name__)
router = APIRouter()

# Initialize services
db = SupabaseService()
rag_service = RAGService()
model = HANONNXInference()


class PredictRequest(BaseModel):
    video_id: str
    video_url: str
    caption: str
    ocr_text: Optional[str] = ""
    stt_text: Optional[str] = ""
    author_id: Optional[str] = None


class TextPredictRequest(BaseModel):
    text: str
    author_id: Optional[str] = None


class PredictResponse(BaseModel):
    video_id: str
    prediction: str
    confidence: float
    method: str
    rag_used: bool
    probabilities: dict
    processing_time_ms: float


@router.post("/predict", response_model=PredictResponse)
async def predict(request: PredictRequest):
    start = time.time()
    
    try:
        logger.info("=" * 70)
        logger.info(f"üì• NEW REQUEST: {request.video_id}")
        
        # =========================
        # VALIDATE INPUT
        # =========================
        if not request.caption or len(request.caption.strip()) == 0:
            logger.error("‚ùå Invalid input: Empty caption")
            raise HTTPException(status_code=400, detail="Caption is required")
        
        # =========================
        # CHECK CACHE
        # =========================
        logger.info(f"üîç Checking cache for video: {request.video_id}")
        cached = db.get_video(request.video_id)
        
        if cached:
            logger.info(f"‚úÖ Cache hit: {request.video_id}")
            logger.info(f"   Cached prediction: {cached['prediction']} ({cached['confidence']:.4f})")
            logger.info(f"   Cached method: {cached.get('method', 'unknown')}")
            
            if cached["prediction"] == "FAKE":
                probs = {"FAKE": cached["confidence"], "REAL": 1 - cached["confidence"]}
            else:
                probs = {"REAL": cached["confidence"], "FAKE": 1 - cached["confidence"]}
            
            processing_time = (time.time() - start) * 1000
            logger.info(f"‚ö° Completed in {processing_time:.0f}ms (cached)")
            logger.info("=" * 70)
            
            return PredictResponse(
                video_id=request.video_id,
                prediction=cached["prediction"],
                confidence=cached["confidence"],
                method="cached",
                rag_used=False,
                probabilities=probs,
                processing_time_ms=processing_time,
            )
        
        logger.info("‚úÖ No cache found, running model...")
        
        # =========================
        # PREPARE INPUT
        # =========================
        title = request.caption.strip()
        
        content_parts = []
        if request.ocr_text and len(request.ocr_text.strip()) > 10:
            content_parts.append(request.ocr_text.strip())
            logger.info(f"   OCR: {len(request.ocr_text)} chars")
        
        if request.stt_text and len(request.stt_text.strip()) > 50:
            content_parts.append(request.stt_text.strip())
            logger.info(f"   STT: {len(request.stt_text)} chars")
        
        content = " ".join(content_parts)[:2000] if content_parts else title
        
        logger.info("üìù Input:")
        logger.info(f"   Title: {title[:100]}...")
        logger.info(f"   Content: {len(content)} chars")
        
        # =========================
        # BASE PREDICTION
        # =========================
        logger.info("ü§ñ Running base model...")
        base_result = model.predict(
            title=title,
            content=content
        )
        
        logger.info(f"   Base result: {base_result['prediction']} ({base_result['confidence']:.4f})")
        logger.info(f"   Probabilities: REAL={base_result['probabilities']['REAL']:.4f}, FAKE={base_result['probabilities']['FAKE']:.4f}")
        
        # =========================
        # RAG VERIFICATION
        # =========================
        rag_used = False
        method = "base_model"
        final_result = base_result
        
        if rag_service.should_use_rag(
            title, 
            content, 
            base_result["confidence"], 
            request.author_id or ""
        ):
            logger.info("üîç Running RAG verification...")
            
            top_chunk = base_result.get('top_chunk', '')
            verification = rag_service.verify_with_sources(
                title=title,
                content=content,
                top_chunk=top_chunk
            )
            
            logger.info(f"   RAG result: {verification['recommendation']}")
            logger.info(f"   Similarity: {verification['similarity_score']:.2f}")
            
            if verification["matching_articles"]:
                rag_used = True
                top_article = verification['matching_articles'][0]
                logger.info(f"   Top match: {top_article['source']}")
                logger.info(f"   Title: {top_article['title'][:80]}...")
                
                similarity = verification["similarity_score"]
                recommendation = verification["recommendation"]
                
                if base_result["prediction"] == "REAL":
                    logger.info("‚úÖ Base REAL, checking RAG confirmation...")
                    
                    if recommendation == "VERIFIED_REAL" and similarity >= 0.8:
                        logger.info(f"‚úÖ VERIFIED_REAL (similarity {similarity:.2f} ‚â• 0.8)")
                        method = "rag_enhanced"
                        boosted_conf = min(0.98, base_result["confidence"] * 1.15)
                        final_result = {
                            "prediction": "REAL",
                            "confidence": boosted_conf,
                            "probabilities": {
                                "REAL": boosted_conf,
                                "FAKE": 1 - boosted_conf,
                            },
                        }
                        logger.info(f"   Boosted: {base_result['confidence']:.4f} ‚Üí {boosted_conf:.4f}")
                    else:
                        logger.info("   RAG did not strongly confirm ‚Üí Keep base")
                        final_result = base_result
                
                elif base_result["prediction"] == "FAKE":
                    logger.info("üîç Base FAKE, checking RAG evidence...")
                    
                    if recommendation == "VERIFIED_REAL" and similarity >= 0.8:
                        logger.warning("‚ö†Ô∏è VERIFIED_REAL (‚â•0.8) ‚Üí Switching to REAL")
                        method = "rag_enhanced"
                        new_conf = max(0.7, min(0.95, 0.7 + (similarity - 0.8) * 3))
                        final_result = {
                            "prediction": "REAL",
                            "confidence": new_conf,
                            "probabilities": {
                                "REAL": new_conf,
                                "FAKE": 1 - new_conf,
                            },
                        }
                        logger.info(f"   Overridden to REAL: {new_conf:.4f}")
                    
                    elif recommendation == "NEEDS_REVIEW" and similarity >= 0.75:
                        logger.warning("‚ö†Ô∏è NEEDS_REVIEW ‚Üí Reducing FAKE confidence")
                        adjusted_conf = max(0.55, base_result["confidence"] * 0.95)
                        final_result = {
                            "prediction": "FAKE",
                            "confidence": adjusted_conf,
                            "probabilities": {
                                "FAKE": adjusted_conf,
                                "REAL": 1 - adjusted_conf,
                            },
                        }
                        logger.info(f"   Adjusted: {adjusted_conf:.4f}")
                    else:
                        logger.info("   No strong evidence ‚Üí Keep base")
                        final_result = base_result
            else:
                logger.info("   No matching articles found ‚Üí Using base result")
                final_result = base_result
        
        # =========================
        # EXTRACT FINAL RESULT
        # =========================
        prediction = final_result["prediction"]
        confidence = final_result["confidence"]
        probabilities = final_result["probabilities"]
        
        logger.info(f"üìä Final result:")
        logger.info(f"   Prediction: {prediction}")
        logger.info(f"   Confidence: {confidence:.4f}")
        logger.info(f"   Method: {method}")
        logger.info(f"   RAG used: {rag_used}")
        
        # =========================
        # SAVE TO CACHE
        # =========================
        try:
            logger.info("üíæ Saving to database...")
            save_data = {
                "video_id": request.video_id,
                "video_url": request.video_url,
                "caption": request.caption,
                "ocr_text": request.ocr_text,
                "stt_text": request.stt_text,
                "author_id": request.author_id,
                "prediction": prediction,
                "confidence": confidence,
                "method": method,
            }
            
            db.save_video(save_data)
            logger.info("‚úÖ Saved to cache")
        
        except Exception as save_error:
            logger.error(f"‚ùå Cache save error: {save_error}")
            logger.warning("‚ö†Ô∏è Continuing without cache...")
        
        # =========================
        # RETURN RESPONSE
        # =========================
        processing_time = (time.time() - start) * 1000
        logger.info(f"‚úÖ Completed in {processing_time:.0f}ms")
        logger.info("=" * 70)
        
        return PredictResponse(
            video_id=request.video_id,
            prediction=prediction,
            confidence=confidence,
            method=method,
            rag_used=rag_used,
            probabilities=probabilities,
            processing_time_ms=processing_time,
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Prediction error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/predict-text", response_model=PredictResponse)
async def predict_text(request: TextPredictRequest):
    """
    Ph√¢n t√≠ch tr·ª±c ti·∫øp m·ªôt ƒëo·∫°n text (kh√¥ng l∆∞u database, v·∫´n d√πng RAG n·∫øu c·∫ßn)
    """
    start = time.time()

    try:
        logger.info("=" * 70)
        logger.info("üì• NEW TEXT REQUEST")

        text = (request.text or "").strip()
        if not text:
            logger.error("‚ùå Invalid input: Empty text")
            raise HTTPException(status_code=400, detail="Text is required")

        # ·ªû ƒë√¢y coi to√†n b·ªô text l√† title + content
        title = text[:200]
        content = text

        logger.info("üìù Text Input:")
        logger.info(f"   Preview: {text[:120]}...")
        logger.info(f"   Length: {len(text)} chars")

        # BASE PREDICTION
        logger.info("ü§ñ Running base model (text)...")
        base_result = model.predict(
            title=title,
            content=content
        )

        logger.info(f"   Base result: {base_result['prediction']} ({base_result['confidence']:.4f})")
        logger.info(
            "   Probabilities: REAL=%.4f, FAKE=%.4f",
            base_result["probabilities"]["REAL"],
            base_result["probabilities"]["FAKE"],
        )

        # RAG VERIFICATION (gi·ªëng lu·ªìng /predict nh∆∞ng kh√¥ng l∆∞u DB)
        rag_used = False
        method = "base_model"
        final_result = base_result

        if rag_service.should_use_rag(
            title,
            content,
            base_result["confidence"],
            request.author_id or "",
        ):
            logger.info("üîç Running RAG verification for text...")

            top_chunk = base_result.get("top_chunk", "")
            verification = rag_service.verify_with_sources(
                title=title,
                content=content,
                top_chunk=top_chunk,
            )

            logger.info(f"   RAG result: {verification['recommendation']}")
            logger.info(f"   Similarity: {verification['similarity_score']:.2f}")

            if verification["matching_articles"]:
                rag_used = True
                top_article = verification["matching_articles"][0]
                logger.info(f"   Top match: {top_article['source']}")
                logger.info(f"   Title: {top_article['title'][:80]}...")

                similarity = verification["similarity_score"]
                recommendation = verification["recommendation"]

                if base_result["prediction"] == "REAL":
                    logger.info("‚úÖ Base REAL, checking RAG confirmation (text)...")

                    if recommendation == "VERIFIED_REAL" and similarity >= 0.8:
                        logger.info(f"‚úÖ VERIFIED_REAL (similarity {similarity:.2f} ‚â• 0.8)")
                        method = "rag_enhanced"
                        boosted_conf = min(0.98, base_result["confidence"] * 1.15)
                        final_result = {
                            "prediction": "REAL",
                            "confidence": boosted_conf,
                            "probabilities": {
                                "REAL": boosted_conf,
                                "FAKE": 1 - boosted_conf,
                            },
                        }
                        logger.info(
                            "   Boosted: %.4f ‚Üí %.4f",
                            base_result["confidence"],
                            boosted_conf,
                        )
                    else:
                        logger.info("   RAG did not strongly confirm ‚Üí Keep base (text)")
                        final_result = base_result

                elif base_result["prediction"] == "FAKE":
                    logger.info("üîç Base FAKE, checking RAG evidence (text)...")

                    if recommendation == "VERIFIED_REAL" and similarity >= 0.8:
                        logger.warning("‚ö†Ô∏è VERIFIED_REAL (‚â•0.8) ‚Üí Switching to REAL (text)")
                        method = "rag_enhanced"
                        new_conf = max(0.7, min(0.95, 0.7 + (similarity - 0.8) * 3))
                        final_result = {
                            "prediction": "REAL",
                            "confidence": new_conf,
                            "probabilities": {
                                "REAL": new_conf,
                                "FAKE": 1 - new_conf,
                            },
                        }
                        logger.info("   Overridden to REAL (text): %.4f", new_conf)

                    elif recommendation == "NEEDS_REVIEW" and similarity >= 0.75:
                        logger.warning("‚ö†Ô∏è NEEDS_REVIEW ‚Üí Reducing FAKE confidence (text)")
                        adjusted_conf = max(0.55, base_result["confidence"] * 0.95)
                        final_result = {
                            "prediction": "FAKE",
                            "confidence": adjusted_conf,
                            "probabilities": {
                                "FAKE": adjusted_conf,
                                "REAL": 1 - adjusted_conf,
                            },
                        }
                        logger.info("   Adjusted (text): %.4f", adjusted_conf)
                    else:
                        logger.info("   No strong evidence ‚Üí Keep base (text)")
                        final_result = base_result
            else:
                logger.info("   No matching articles found ‚Üí Using base result (text)")
                final_result = base_result

        prediction = final_result["prediction"]
        confidence = final_result["confidence"]
        probabilities = final_result["probabilities"]

        logger.info("üìä Final text result:")
        logger.info("   Prediction: %s", prediction)
        logger.info("   Confidence: %.4f", confidence)
        logger.info("   Method: %s", method)
        logger.info("   RAG used: %s", rag_used)

        processing_time = (time.time() - start) * 1000
        logger.info("‚úÖ Completed text analysis in %.0fms", processing_time)
        logger.info("=" * 70)

        # video_id tr·∫£ v·ªÅ gi√° tr·ªã gi·∫£ ƒë·ªÉ UI kh√¥ng b·ªã l·ªói nh∆∞ng kh√¥ng d√πng ƒë·∫øn
        return PredictResponse(
            video_id="TEXT_INPUT",
            prediction=prediction,
            confidence=confidence,
            method=method,
            rag_used=rag_used,
            probabilities=probabilities,
            processing_time_ms=processing_time,
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Text prediction error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
