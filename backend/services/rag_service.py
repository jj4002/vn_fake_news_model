# services/rag_service.py
from typing import Optional, Dict, List
import logging
import os

logger = logging.getLogger(__name__)

try:
    from sentence_transformers import SentenceTransformer
    EMBEDDINGS_AVAILABLE = True
except ImportError:
    EMBEDDINGS_AVAILABLE = False
    logger.warning("sentence-transformers not available, RAG disabled")

from services.supabase_client import SupabaseService  # ‚Üê CH·ªà C·∫¶N C√ÅI N√ÄY

class RAGService:
    """Retrieval-Augmented Generation service"""
    
    def __init__(self):
        self.supabase = SupabaseService()
        self.available = EMBEDDINGS_AVAILABLE
        
        if self.available:
            try:
                model_name = os.getenv("EMBEDDING_MODEL", "keepitreal/vietnamese-sbert")
                # Auto-detect CUDA for RAG SentenceTransformer
                try:
                    import torch
                    if torch.cuda.is_available():
                        device = 'cuda'
                        logger.info(f"‚úÖ RAG using GPU: {torch.cuda.get_device_name(0)}")
                    else:
                        device = 'cpu'
                        logger.info("‚ö†Ô∏è RAG using CPU (CUDA not available)")
                except:
                    device = 'cpu'
                    logger.info("‚ö†Ô∏è RAG using CPU")
                
                self.embedding_model = SentenceTransformer(model_name, device=device)
                logger.info(f"‚úÖ RAG enabled with {model_name} (device: {device})")
            except Exception as e:
                logger.error(f"Failed to load embedding model: {e}")
                self.available = False
        else:
            self.embedding_model = None
            logger.warning("RAG service disabled")
    
    def should_use_rag(self, title: str, content: str, base_confidence: float, author_id: str = "") -> bool:
        """Decide whether to use RAG"""
        
        if not self.available:
            return False
        
        text_lower = (title + ' ' + content).lower()
        
        # Rule 1: High confidence predictions (verify)
        if base_confidence > 0.95:
            logger.info("RAG triggered: Very high confidence - needs verification")
            return True
        
        # Rule 2: Clickbait patterns
        clickbait_keywords = [
            'ngay l·∫≠p t·ª©c', 'kh·∫©n', 'n√≥ng', 's·ªëc', 'ch·∫•n ƒë·ªông',
            'tr∆∞·ªõc', 'b·ªã ph·∫°t', 'ti·ªÅn tri·ªáu', 'h√£y v√†o', 
            'ki·ªÉm tra ngay', 'c·∫£nh b√°o', 'b√≠ m·∫≠t'
        ]
        clickbait_count = sum(1 for kw in clickbait_keywords if kw in text_lower)
        
        if clickbait_count >= 3:
            logger.info(f"RAG triggered: Clickbait detected ({clickbait_count} keywords)")
            return True
        
        # Rule 3: Sensitive topics prone to misinformation
        sensitive_keywords = [
            # Ch√≠nh s√°ch t√†i ch√≠nh - "Nh√† n∆∞·ªõc t·∫∑ng ti·ªÅn"
            't·∫∑ng ti·ªÅn', 'ph√°t ti·ªÅn', 'h·ªó tr·ª£ ti·ªÅn m·∫∑t', 'nh·∫≠n ti·ªÅn',
            'b·ªô t√†i ch√≠nh ph√°t', 'ch√≠nh ph·ªß t·∫∑ng', 'm·ªói ng∆∞·ªùi d√¢n',
            'tr·ª£ c·∫•p', 'ti·ªÅn h·ªó tr·ª£', 'ti·ªÅn th∆∞·ªüng',
            
            # Y t·∫ø - B·ªánh m·ªõi, thu·ªëc th·∫ßn k·ª≥, vaccine
            'virus m·ªõi', 'b·ªánh l·∫°', 'd·ªãch b·ªánh', 'b√πng ph√°t',
            'vaccine nguy hi·ªÉm', 'v√¥ sinh', 'ch·∫øt sau ti√™m',
            'thu·ªëc ch·ªØa kh·ªèi', 'b√≠ quy·∫øt ch·ªØa', 'ph∆∞∆°ng ph√°p th·∫ßn k·ª≥',
            'tay ch√¢n mi·ªáng', 'covid', 'c√∫m', 'ung th∆∞',
            
            # Ch√≠nh tr·ªã - Ph√°t ng√¥n, ƒë·∫£o ng∆∞·ª£c s·ª± ki·ªán
            'b·ªô tr∆∞·ªüng', 't·ªïng b√≠ th∆∞', 'th·ªß t∆∞·ªõng', 'ch·ªß t·ªãch',
            't·ª´ ch·ª©c', 'b√™ b·ªëi', 'tham nh≈©ng', 'b√≠ m·∫≠t',
            'thu h·ªìi ƒë·∫•t', 'c∆∞·ª°ng ch·∫ø', 'bi·ªÉu t√¨nh',
            
            # Thi√™n tai - Th·ªïi ph·ªìng
            'ƒë·ªông ƒë·∫•t', 'l≈© l·ª•t', 'ng·∫≠p l·ª•t', 's√≥ng th·∫ßn',
            'b√£o l·ªõn', 'si√™u b√£o', 'th·∫£m h·ªça', 's·∫°t l·ªü',
            'h√†ng trƒÉm ng∆∞·ªùi ch·∫øt', 'h√†ng ng√†n n·∫°n nh√¢n',
            
            # Kinh t·∫ø - Ng√¢n h√†ng, ph√° s·∫£n
            'ng√¢n h√†ng s·ª•p ƒë·ªï', 'ph√° s·∫£n', 'v·ª° n·ª£', 'r√∫t ti·ªÅn',
            'bitcoin tƒÉng', 'ƒë·∫ßu t∆∞ ngay', 'l√†m gi√†u nhanh',
            'c·ªï phi·∫øu s·ª•p', 'kh·ªßng ho·∫£ng t√†i ch√≠nh',
            
            # Gi√°o d·ª•c - Thi c·ª≠, ch√≠nh s√°ch
            'b·ªè thi', 'mi·ªÖn h·ªçc ph√≠', 'thay ƒë·ªïi quy ƒë·ªãnh',
            't·ªët nghi·ªáp thpt', 'ƒëi·ªÉm chu·∫©n', 'x√©t tuy·ªÉn',
            'b·ªô gi√°o d·ª•c', 'c·∫•m h·ªçc sinh',
            
            # X√£ h·ªôi - T·ªôi ph·∫°m, b·∫Øt c√≥c
            'b·∫Øt c√≥c tr·∫ª em', 'x√¢m h·∫°i', 'c∆∞·ªõp gi·∫≠t',
            'ng∆∞·ªùi l·∫°', 'nghi ph·∫°m', 't·ªôi ph·∫°m',
            'm·∫•t t√≠ch', 'n·∫°n nh√¢n', 'ƒë√°nh ng∆∞·ªùi',
            
            # Ch√≠nh ph·ªß & C∆° quan (t·ª´ Rule 3 c≈©)
            'vneid', 'ch√≠nh ph·ªß', 'b·ªô', 'c√¥ng an',
            'th√¥ng b√°o ch√≠nh th·ª©c', 'quy ƒë·ªãnh', 'lu·∫≠t',
            'bhyt', 'bhxh', 'cccd'
        ]
        if any(kw in text_lower for kw in sensitive_keywords):
            logger.info("RAG triggered: Official topic - needs verification")
            return True
        
        # Rule 4: Breaking news
        breaking_keywords = [
            # Urgency - Kh·∫©n c·∫•p
            'kh·∫©n c·∫•p', 'v·ª´a xong', 'breaking', 'm·ªõi nh·∫•t', 'tin n√≥ng',
            
            # Time sensitivity - Th·ªùi gian
            'ngay l√∫c n√†y', 'ngay b√¢y gi·ªù', 'hi·ªán t·∫°i', 'ƒëang di·ªÖn ra',
            'v·ª´a m·ªõi', 'ph√∫t tr∆∞·ªõc', 'gi·ªù tr∆∞·ªõc', 'h√¥m nay',
            
            # Emergency - Kh·∫©n
            'c·∫ßn ngay', 'l·∫≠p t·ª©c', 'g·∫•p', 'h·ªèa t·ªëc', 'kh·∫©n',
            
            # Alerts - C·∫£nh b√°o
            'c·∫£nh b√°o kh·∫©n', 'th√¥ng b√°o kh·∫©n', 'b√°o ƒë·ªông', 
            'tai n·∫°n', 'th·∫£m h·ªça', 'nguy hi·ªÉm',
            
            # Updates - C·∫≠p nh·∫≠t
            'c·∫≠p nh·∫≠t m·ªõi nh·∫•t', 'tin m·ªõi', 'v·ª´a ph√°t hi·ªán',
            'th√¥ng tin m·ªõi', 'di·ªÖn bi·∫øn m·ªõi'
        ]
        if any(kw in text_lower for kw in breaking_keywords):
            logger.info("RAG triggered: Breaking news")
            return True
        
        # Rule 5: Unknown source with high confidence
        trusted_sources = ['vnexpress', 'vtv', 'vov', '60giay', 'thuvienphapluat']
        is_trusted = any(source in author_id.lower() for source in trusted_sources)
        
        if not is_trusted and base_confidence > 0.8:
            logger.info("RAG triggered: Unknown source with high confidence")
            return True
        
        return False
    
    def verify_with_sources(self, title: str, content: str, top_chunk: str = None, top_k: int = 5) -> Dict:
        if not self.available:
            return {
                "has_reliable_source": False,
                "similarity_score": 0.0,
                "matching_articles": [],
                "recommendation": "NO_RELIABLE_SOURCE_FOUND",
            }
        
        try:
            # Query generation v·ªõi overlap chunk t·ª´ top_chunk (n·∫øu c√≥)
            if top_chunk and len(top_chunk.strip()) > 20:
                raw_chunk = top_chunk.strip()

                # Chia top_chunk th√†nh nhi·ªÅu ƒëo·∫°n ch·ªìng l·∫•n nhau ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c nhi·ªÅu ng·ªØ c·∫£nh h∆°n
                window_size = 300   # s·ªë k√Ω t·ª± m·ªói c·ª≠a s·ªï
                overlap = 100       # s·ªë k√Ω t·ª± ch·ªìng l·∫•n
                max_windows = 3     # ch·ªâ l·∫•y t·ªëi ƒëa 3 c·ª≠a s·ªï ƒë·ªÉ query kh√¥ng qu√° d√†i

                windows = []
                start = 0
                while start < len(raw_chunk) and len(windows) < max_windows:
                    end = min(len(raw_chunk), start + window_size)
                    windows.append(raw_chunk[start:end])
                    if end >= len(raw_chunk):
                        break
                    start = end - overlap

                query_text = f"{title} " + " ".join(windows)
                logger.info(
                    "üîç RAG Query: Using title + overlap chunks from top_chunk "
                    f"(len={len(raw_chunk)}, windows={len(windows)})"
                )
            else:
                query_text = f"{title} {content[:500]}"
                logger.info(f"üîç RAG Query: Using title + content preview (fallback)")
            
            query_text = query_text[:1000]
            query_embedding = self.embedding_model.encode(
                query_text,
                normalize_embeddings=True,
            )
            
            # ========================================
            # FIX: TƒÇNG THRESHOLD L√äN 0.75
            # ========================================
            results = self.supabase.search_similar_news(
                query_embedding,
                top_k=top_k,
                threshold=0.75,  # ‚Üê THAY ƒê·ªîI T·ª™ 0.65 ‚Üí 0.75
            )
            
            if not results:
                logger.info("‚ùå No matching real news found (threshold: 0.75)")
                return {
                    "has_reliable_source": False,
                    "similarity_score": 0.0,
                    "matching_articles": [],
                    "recommendation": "NO_RELIABLE_SOURCE_FOUND",
                }
            
            best_match = results[0]
            similarity = best_match.get("similarity", 0.0)
            
            logger.info(f"‚úÖ Found {len(results)} matching articles")
            logger.info(f"   Best match: {best_match['source']} (similarity: {similarity:.2f})")
            logger.info(f"   Title: {best_match['title'][:80]}...")
            
            # ========================================
            # FIX: RECOMMENDATION LOGIC M·ªöI
            # ========================================
            
            # Tier 1: Very High Confidence (0.8+)
            if similarity >= 0.80:
                recommendation = "VERIFIED_REAL"
                has_source = True
                logger.info("   ‚úÖ VERIFIED_REAL (similarity ‚â• 0.80)")
            
            # Tier 2: High Confidence (0.75-0.8)
            elif similarity >= 0.75:
                recommendation = "NEEDS_REVIEW"
                has_source = True
                logger.info("   ‚ö†Ô∏è NEEDS_REVIEW (0.75 ‚â§ similarity < 0.8)")
            
            # Tier 3: Below threshold
            else:
                recommendation = "NO_RELIABLE_SOURCE_FOUND"
                has_source = False
                logger.info("   ‚ùå NO_RELIABLE_SOURCE (similarity < 0.75)")
            
            return {
                "has_reliable_source": has_source,
                "similarity_score": similarity,
                "matching_articles": results[:3],
                "recommendation": recommendation,
            }
        
        except Exception as e:
            logger.error(f"‚ùå RAG verification error: {e}", exc_info=True)
            return {
                "has_reliable_source": False,
                "similarity_score": 0.0,
                "matching_articles": [],
                "recommendation": "NO_RELIABLE_SOURCE_FOUND",
            }

    def retrieve_context(self, title: str, content: str, top_k: int = 3) -> Optional[str]:
        """Retrieve similar news articles (legacy method)"""
        
        verification = self.verify_with_sources(title, content, top_k)
        
        if not verification['matching_articles']:
            return None
        
        # Build context string
        context_parts = []
        for article in verification['matching_articles']:
            snippet = f"[{article['source']}] {article['title']}"
            context_parts.append(snippet)
        
        return " | ".join(context_parts)
