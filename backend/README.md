# Backend API Server

FastAPI server cung cáº¥p API Ä‘á»ƒ phÃ¡t hiá»‡n tin giáº£ trÃªn TikTok vá»›i cÃ¡c tÃ­nh nÄƒng ML/AI tiÃªn tiáº¿n.

## ðŸ“‹ Tá»•ng quan

Backend nÃ y cung cáº¥p:
- **Prediction API**: Dá»± Ä‘oÃ¡n tin giáº£/tháº­t tá»« video TikTok
- **Media Processing**: OCR vÃ  Speech-to-Text tá»« video
- **RAG Verification**: XÃ¡c minh vá»›i nguá»“n tin Ä‘Ã¡ng tin cáº­y
- **Caching**: LÆ°u káº¿t quáº£ Ä‘á»ƒ tá»‘i Æ°u performance
- **Reporting**: Há»‡ thá»‘ng bÃ¡o cÃ¡o Ä‘á»ƒ cáº£i thiá»‡n model

## ðŸ—ï¸ Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI    â”‚
â”‚   (main.py)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”
   â”‚       â”‚
   â–¼       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Routerâ”‚ â”‚ Services â”‚
â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
   â”‚          â”‚
   â”‚    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
   â”‚    â”‚           â”‚
   â–¼    â–¼           â–¼
â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Predâ”‚ â”‚Med â”‚ â”‚   RAG    â”‚
â”‚ict â”‚ â”‚ia  â”‚ â”‚ Service  â”‚
â””â”€â”€â”¬â”€â”˜ â””â”€â”€â”¬â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
   â”‚      â”‚         â”‚
   â”‚      â”‚         â”‚
   â–¼      â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚HAN   â”‚ â”‚OCR/  â”‚ â”‚ Supabase â”‚
â”‚Model â”‚ â”‚STT   â”‚ â”‚   DB     â”‚
â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
backend/
â”œâ”€â”€ main.py                 # FastAPI app entry point
â”œâ”€â”€ requirement.txt          # Python dependencies
â”‚
â”œâ”€â”€ routers/                # API endpoints
â”‚   â”œâ”€â”€ predict.py          # Prediction endpoint
â”‚   â”œâ”€â”€ media.py            # Media processing endpoint
â”‚   â””â”€â”€ reports.py          # Reporting endpoint
â”‚
â”œâ”€â”€ services/               # Business logic
â”‚   â”œâ”€â”€ inference.py        # HAN model inference
â”‚   â”œâ”€â”€ rag_service.py      # RAG verification
â”‚   â”œâ”€â”€ media_processor.py  # Video/image processing
â”‚   â”œâ”€â”€ ocr_service.py     # OCR service
â”‚   â”œâ”€â”€ stt_service.py     # Speech-to-Text service
â”‚   â””â”€â”€ supabase_client.py # Database client
â”‚
â””â”€â”€ scripts/                # Utility scripts
    â”œâ”€â”€ generate_embeddings.py
    â””â”€â”€ regenerate_embeddings.py
```

## ðŸš€ CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirement.txt
```

**Key dependencies:**
- `fastapi`: Web framework
- `uvicorn`: ASGI server
- `onnxruntime`: Model inference
- `sentence-transformers`: Embeddings
- `supabase`: Database client
- `vietocr`: Vietnamese OCR
- `openai-whisper`: Speech-to-Text
- `yt-dlp`: Video download
- `opencv-python`: Image processing
- `moviepy`: Audio extraction

### 2. Cáº¥u hÃ¬nh Environment Variables

Táº¡o file `.env`:

```env
# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-service-role-key

# Model paths
MODEL_PATH=./models/han_rag_model.onnx
TOKENIZER_PATH=vinai/phobert-base-v2
EMBEDDING_MODEL=keepitreal/vietnamese-sbert

# Server
PORT=8000
HOST=0.0.0.0
```

### 3. Setup Database

Cháº¡y SQL schema tá»« `extension/database/supabase_schema.sql` trÃªn Supabase.

### 4. Cháº¡y server

```bash
python main.py
```

Hoáº·c vá»›i uvicorn:
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Server sáº½ cháº¡y táº¡i: `http://localhost:8000`

API docs: `http://localhost:8000/docs`

## ðŸ“ API Endpoints

### 1. Health Check

```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "model": "loaded",
  "database": "connected"
}
```

### 2. Predict (`/api/v1/predict`)

Dá»± Ä‘oÃ¡n tin giáº£/tháº­t tá»« video TikTok.

**Request:**
```json
{
  "video_id": "1234567890",
  "video_url": "https://tiktok.com/@user/video/123",
  "caption": "Video caption text...",
  "ocr_text": "Text extracted from video frames...",
  "stt_text": "Transcribed audio text...",
  "author_id": "username"
}
```

**Response:**
```json
{
  "video_id": "1234567890",
  "prediction": "FAKE",
  "confidence": 0.85,
  "method": "rag_enhanced",
  "rag_used": true,
  "probabilities": {
    "REAL": 0.15,
    "FAKE": 0.85
  },
  "processing_time_ms": 1234.5
}
```

**Prediction Methods:**
- `cached`: Káº¿t quáº£ tá»« cache
- `base_model`: Chá»‰ dÃ¹ng HAN model
- `rag_enhanced`: CÃ³ sá»­ dá»¥ng RAG verification

### 3. Process Media (`/api/v1/process-media`)

Xá»­ lÃ½ media Ä‘á»ƒ extract OCR vÃ  STT.

**Request:**
```json
{
  "video_id": "1234567890",
  "video_url": "https://tiktok.com/@user/video/123"
}
```

**Response:**
```json
{
  "video_id": "1234567890",
  "ocr_text": "Text from OCR...",
  "stt_text": "Text from STT...",
  "processing_time_ms": 5678.9
}
```

### 4. Report (`/api/v1/report`)

BÃ¡o cÃ¡o káº¿t quáº£ prediction sai.

**Request:**
```json
{
  "video_id": "1234567890",
  "reported_prediction": "FAKE",
  "reason": "Optional reason text..."
}
```

**Response:**
```json
{
  "status": "success",
  "message": "Report saved successfully"
}
```

### 5. Get Pending Reports (`/api/v1/reports/pending`)

Láº¥y danh sÃ¡ch reports Ä‘ang chá» review (admin).

**Query params:**
- `limit`: Sá»‘ lÆ°á»£ng reports (default: 50)

## ðŸ”§ Services Chi tiáº¿t

### Inference Service (`services/inference.py`)

**HANONNXInference Class:**
- Load ONNX model
- Text normalization (Vietnamese)
- Chunk selection vá»›i RAG
- Model prediction

**Methods:**
- `predict(title, content)`: Dá»± Ä‘oÃ¡n vá»›i HAN model
- `_select_chunks_with_rag()`: Chá»n chunks quan trá»ng

### RAG Service (`services/rag_service.py`)

**RAGService Class:**
- Vector similarity search
- Verification vá»›i news corpus
- Confidence adjustment

**Methods:**
- `should_use_rag()`: Quyáº¿t Ä‘á»‹nh cÃ³ dÃ¹ng RAG khÃ´ng
- `verify_with_sources()`: TÃ¬m kiáº¿m vÃ  verify

**RAG Triggers:**
- High confidence (>0.95)
- Clickbait patterns
- Sensitive topics
- Breaking news keywords
- Unknown source vá»›i high confidence

### Media Processor (`services/media_processor.py`)

**MediaProcessor Class:**
- Download video/image tá»« TikTok
- Extract frames cho OCR
- Extract audio cho STT

**Methods:**
- `download_media()`: Download vá»›i yt-dlp
- `extract_frames()`: Extract frames tá»« video
- `extract_audio()`: Extract audio track

### OCR Service (`services/ocr_service.py`)

**OCRService Class:**
- Sá»­ dá»¥ng VietOCR (Vietnamese optimized)
- Extract text tá»« frames/images

**Methods:**
- `extract_text_from_frames()`: OCR tá»« video frames
- `extract_text_from_image()`: OCR tá»« image

### STT Service (`services/stt_service.py`)

**STTService Class:**
- Sá»­ dá»¥ng OpenAI Whisper (large-v3)
- Transcribe audio sang text

**Methods:**
- `transcribe_audio()`: Speech-to-Text

### Supabase Client (`services/supabase_client.py`)

**SupabaseService Class:**
- Database operations
- Vector search
- Caching

**Methods:**
- `get_video()`: Láº¥y cached prediction
- `save_video()`: LÆ°u prediction
- `search_similar_news()`: Vector similarity search
- `save_report()`: LÆ°u user report

## ðŸ§ª Testing

### Test vá»›i curl

```bash
# Health check
curl http://localhost:8000/health

# Predict
curl -X POST http://localhost:8000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{
    "video_id": "test123",
    "video_url": "https://tiktok.com/@test/video/123",
    "caption": "Test caption"
  }'
```

### Test vá»›i Python

```python
import requests

response = requests.post(
    "http://localhost:8000/api/v1/predict",
    json={
        "video_id": "test123",
        "video_url": "https://tiktok.com/@test/video/123",
        "caption": "Test caption"
    }
)
print(response.json())
```

## ðŸ“Š Performance

### Benchmarks

- **Prediction (no cache)**: ~1-3 giÃ¢y
- **Prediction (cached)**: <100ms
- **Media processing**: ~5-10 giÃ¢y
- **RAG search**: ~500ms-1s

### Optimization

1. **Caching**: Káº¿t quáº£ Ä‘Æ°á»£c cache trong database
2. **Batch processing**: CÃ³ thá»ƒ batch process media
3. **Async operations**: FastAPI async support
4. **Model optimization**: ONNX Runtime cho inference nhanh

## ðŸ› Troubleshooting

### Model khÃ´ng load

**Váº¥n Ä‘á»:** `FileNotFoundError: Model not found`
- **Giáº£i phÃ¡p:** Kiá»ƒm tra `MODEL_PATH` trong `.env`

### Database connection failed

**Váº¥n Ä‘á»:** `Supabase connection failed`
- **Giáº£i phÃ¡p:** Kiá»ƒm tra `SUPABASE_URL` vÃ  `SUPABASE_KEY`

### OCR/STT khÃ´ng hoáº¡t Ä‘á»™ng

**Váº¥n Ä‘á»:** `VietOCR/Whisper not available`
- **Giáº£i phÃ¡p:** 
  - CÃ i Ä‘áº·t dependencies: `pip install vietocr openai-whisper`
  - Kiá»ƒm tra FFmpeg Ä‘Ã£ cÃ i Ä‘áº·t

### Memory issues

**Váº¥n Ä‘á»:** Out of memory khi process media
- **Giáº£i phÃ¡p:**
  - Giáº£m sá»‘ frames cho OCR
  - Sá»­ dá»¥ng GPU náº¿u cÃ³
  - TÄƒng swap space

## ðŸ”’ Security

- **CORS**: Configured cho extension origin
- **Input validation**: Pydantic models
- **SQL injection**: Supabase client tá»± Ä‘á»™ng escape
- **RLS**: Row Level Security trÃªn database

## ðŸ“ˆ Monitoring

### Logging

Server sá»­ dá»¥ng Python logging:
- Level: INFO
- Format: Timestamp, level, message
- Output: Console

### Metrics (cÃ³ thá»ƒ thÃªm)

- Request count
- Response time
- Error rate
- Cache hit rate

## ðŸ”® Future Improvements

- [ ] WebSocket support cho real-time updates
- [ ] Batch prediction API
- [ ] Model versioning
- [ ] A/B testing framework
- [ ] Prometheus metrics
- [ ] Distributed caching (Redis)
- [ ] GPU support cho inference

## ðŸ“„ License

MIT License

